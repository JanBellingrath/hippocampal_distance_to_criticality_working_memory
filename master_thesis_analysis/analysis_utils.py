import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import display


def calculate_between_area_correlations_same_chunk(df, n_permutations=1000):
    """
    Calculates correlations between CA1 and CA3 at matching time chunks with permutation tests.
    All outputs not explicitly generated by this function are suppressed.
    
    Parameters:
    -----------
    df : pandas DataFrame
        Input DataFrame containing time series data
    n_permutations : int
        Number of permutations for the null distribution
    """
    # Set up context managers to suppress unwanted outputs
    import warnings
    import matplotlib.pyplot as plt
    from contextlib import contextmanager
    
    @contextmanager
    def suppress_outputs():
        """Context manager to suppress unwanted outputs"""
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            plt.ioff()  # Turn off interactive plotting
            yield
            plt.ion()  # Turn interactive plotting back on
    
    # Run the analysis with suppressed outputs
    with suppress_outputs():
        # Initialize storage
        correlations = {'tau': [], 'm': []}
        null_mean_correlations = {'tau': [], 'm': []}
        
        # Calculate observed correlations
        for name, group in df.groupby(['animal', 'day', 'epoch']):
            if len(group) >= 10:  # Filter for at least 10 time chunks within each epoch
                ca1_data = group[group['area'] == 'CA1']
                ca3_data = group[group['area'] == 'CA3']
                    
            # Merge data on time chunk to ensure matching time chunks
            merged_data = pd.merge(ca1_data, ca3_data, on='time_chunk', how='inner')
            
            # Extract tau and branching factor values for merged data
            ca1_tau = merged_data['tau_x'].values
            ca3_tau = merged_data['tau_y'].values
            ca1_m = merged_data['branching_factor_x'].values
            ca3_m = merged_data['branching_factor_y'].values
            
            # Calculate correlations
            tau_corr = np.corrcoef(ca1_tau, ca3_tau)[0,1]
            m_corr = np.corrcoef(ca1_m, ca3_m)[0,1]
            
            if not np.isnan(tau_corr):
                correlations['tau'].append(tau_corr)
            if not np.isnan(m_corr):
                correlations['m'].append(m_corr)
        
        # Permutation test
        for perm in range(n_permutations):
            perm_correlations = {'tau': [], 'm': []}
            
            for name, group in df.groupby(['animal', 'day', 'epoch']):
                ca1_data = group[group['area'] == 'CA1']
                ca3_data = group[group['area'] == 'CA3']
                
                if len(ca1_data) > 0 and len(ca3_data) > 0:
                    min_len = min(len(ca1_data), len(ca3_data))
                    
                    # Get and shuffle time series
                    ca1_tau = np.random.permutation(ca1_data['tau'].values[:min_len])
                    ca3_tau = np.random.permutation(ca3_data['tau'].values[:min_len])
                    ca1_m = np.random.permutation(ca1_data['branching_factor'].values[:min_len])
                    ca3_m = np.random.permutation(ca3_data['branching_factor'].values[:min_len])
                    
                    # Calculate shuffled correlations
                    tau_corr_null = np.corrcoef(ca1_tau, ca3_tau)[0,1]
                    m_corr_null = np.corrcoef(ca1_m, ca3_m)[0,1]
                    
                    if not np.isnan(tau_corr_null):
                        perm_correlations['tau'].append(tau_corr_null)
                    if not np.isnan(m_corr_null):
                        perm_correlations['m'].append(m_corr_null)
            
            # Store mean of permutation
            if perm_correlations['tau']:
                null_mean_correlations['tau'].append(np.mean(perm_correlations['tau']))
            if perm_correlations['m']:
                null_mean_correlations['m'].append(np.mean(perm_correlations['m']))
    
    # Create explicit outputs (these will be shown)
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # Plot distributions
    measures = ['tau', 'm']
    titles = ['Neural Timescale', 'Branching Factor']
    
    for i, (measure, title) in enumerate(zip(measures, titles)):
        # Observed distribution
        sns.histplot(data=correlations[measure], kde=True, ax=axes[i], 
                    color='#2c7bb6', alpha=0.5, label='Observed data distribution')
        
        # Null distribution
        sns.histplot(data=null_mean_correlations[measure], kde=True, ax=axes[i],
                    color='orange', alpha=0.3, label='Null mean distribution')
        
        # Add mean line
        axes[i].axvline(np.mean(correlations[measure]), color='red', linestyle='--',
                       label=f'Mean: {np.mean(correlations[measure]):.3f}')
        
        axes[i].set_title(f'CA1-CA3 {title} Correlations')
        axes[i].set_xlabel('Correlation Coefficient')
        axes[i].set_ylabel('Count')
        axes[i].legend()
    
    plt.tight_layout()
    
    # Create formatted results table
    formatted_data = []
    for measure, title in zip(measures, titles):
        observed_mean = np.mean(correlations[measure])
        null_means = null_mean_correlations[measure]
        p_value = np.mean(np.abs(null_means) >= np.abs(observed_mean))
        
        formatted_data.append({
            'Measure': title,
            'Observed Mean': f"{observed_mean:.3f}",
            'Null Mean': f"{np.mean(null_means):.3f}",
            'p-value': f"{p_value:.10e}",
            'CI 95%': f"[{np.percentile(null_means, 2.5):.3f}, {np.percentile(null_means, 97.5):.3f}]"
        })

    # Create DataFrame
    table_df = pd.DataFrame(formatted_data)
    
    # Apply styling
    styled_df = (table_df.style
                .set_properties(**{
                    'text-align': 'center',
                    'font-size': '11pt',
                    'font-family': 'Arial',
                    'border': '2px solid black'
                })
                .set_table_styles([
                    {'selector': 'table',
                     'props': [('border', '2px solid black')]},
                    {'selector': 'th',
                     'props': [('background-color', '#f0f0f0'),
                             ('font-weight', 'bold'),
                             ('text-align', 'center'),
                             ('border-bottom', '2px solid black'),
                             ('white-space', 'pre-wrap')]},
                    {'selector': 'td',
                     'props': [('white-space', 'pre-wrap')]},
                    {'selector': 'caption',
                     'props': [('caption-side', 'top'),
                             ('font-size', '14pt'),
                             ('font-weight', 'bold'),
                             ('margin-bottom', '10px')]}
                ])
                .set_caption('CA1-CA3 Correlation Analysis Results')
                .hide(axis='index'))
    
    # Display the styled table
    display(styled_df)
    
    return {
        'correlations': correlations,
        'null_mean_correlations': null_mean_correlations,
        'figure': fig,
        'styled_results': styled_df
    }

def calculate_within_area_autocorrelations(df, n_permutations=1000):
    """
    Calculates autocorrelations with permutation tests for significance.
    Corrected to compute null distributions of mean autocorrelations.
    
    Parameters:
    -----------
    df : pandas DataFrame
        Input DataFrame containing time series data
    n_permutations : int
        Number of permutations for the null distribution
    """
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    from contextlib import contextmanager
    import warnings

    @contextmanager
    def suppress_outputs():
        """Context manager to suppress unwanted outputs"""
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            plt.ioff()  # Turn off interactive plotting
            yield
            plt.ion()  # Turn interactive plotting back on

    # Run the analysis with suppressed outputs
    with suppress_outputs():
        # Initialize storage
        tau_autocorrs = {'CA1': [], 'CA3': []}
        m_autocorrs = {'CA1': [], 'CA3': []}
        null_mean_autocorrs = {'CA1': {'tau': [], 'm': []}, 'CA3': {'tau': [], 'm': []}}
        
        areas = ['CA1', 'CA3']
        
        # Calculate observed autocorrelations
        for area in areas:
            area_tau_autocorrs = []
            area_m_autocorrs = []
            area_groups = df[df['area'] == area].groupby(['animal', 'day', 'epoch'])
            
            for name, group in area_groups:
                group_sorted = group.sort_values('time_chunk')
                if len(group_sorted) > 10:
                    # Merge data on time chunk to ensure matching time chunks
                    merged_data = pd.merge(group_sorted, group_sorted, on='time_chunk', how='inner', suffixes=('_x', '_y'))
                    
                    # Extract tau and branching factor values for merged data
                    tau_series = merged_data['tau_x'].values
                    m_series = merged_data['branching_factor_x'].values
                    
                    # Calculate autocorrelations
                    tau_autocorr = np.corrcoef(tau_series[:-1], tau_series[1:])[0,1]
                    m_autocorr = np.corrcoef(m_series[:-1], m_series[1:])[0,1]
                    
                    if not np.isnan(tau_autocorr):
                        area_tau_autocorrs.append(tau_autocorr)
                    if not np.isnan(m_autocorr):
                        area_m_autocorrs.append(m_autocorr)
            
            tau_autocorrs[area] = area_tau_autocorrs
            m_autocorrs[area] = area_m_autocorrs
        
        # Permutation test
        for perm in range(n_permutations):
            for area in areas:
                perm_tau_autocorrs = []
                perm_m_autocorrs = []
                area_groups = df[df['area'] == area].groupby(['animal', 'day', 'epoch'])
                
                for name, group in area_groups:
                    group_sorted = group.sort_values('time_chunk')
                    if len(group_sorted) > 10:
                        tau_series = group_sorted['tau'].values
                        m_series = group_sorted['branching_factor'].values

                        # Shuffle the series
                        tau_shuffled = np.random.permutation(tau_series)
                        m_shuffled = np.random.permutation(m_series)

                        # Calculate shuffled autocorrelations
                        tau_autocorr_null = np.corrcoef(tau_shuffled[:-1], tau_shuffled[1:])[0,1]
                        m_autocorr_null = np.corrcoef(m_shuffled[:-1], m_shuffled[1:])[0,1]

                        if not np.isnan(tau_autocorr_null):
                            perm_tau_autocorrs.append(tau_autocorr_null)
                        if not np.isnan(m_autocorr_null):
                            perm_m_autocorrs.append(m_autocorr_null)
                
                # Compute mean autocorrelation for this permutation
                if perm_tau_autocorrs:
                    null_mean_autocorrs[area]['tau'].append(np.mean(perm_tau_autocorrs))
                if perm_m_autocorrs:
                    null_mean_autocorrs[area]['m'].append(np.mean(perm_m_autocorrs))
        
        # Create figure with 4 subplots (2x2)
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Plot observed distributions
        for i, area in enumerate(areas):
            sns.histplot(data=tau_autocorrs[area], kde=True, ax=axes[0,0], 
                         label=area, alpha=0.5)
            sns.histplot(data=m_autocorrs[area], kde=True, ax=axes[0,1], 
                         label=area, alpha=0.5)
        
        axes[0,0].set_title('Observed Tau Autocorrelations by Area')
        axes[0,0].set_xlabel('Autocorrelation Coefficient (τ)')
        axes[0,0].set_ylabel('Count')
        axes[0,0].legend()
        
        axes[0,1].set_title('Observed Branching Factor Autocorrelations by Area')
        axes[0,1].set_xlabel('Autocorrelation Coefficient (m)')
        axes[0,1].set_ylabel('Count')
        axes[0,1].legend()
        
        # Plot null distributions with observed means
        for area in areas:
            # Tau null distribution
            sns.histplot(data=null_mean_autocorrs[area]['tau'], kde=True, ax=axes[1,0],
                         label=f'{area} null', alpha=0.3)
            axes[1,0].axvline(np.mean(tau_autocorrs[area]), color='r' if area=='CA1' else 'g',
                              linestyle='--', label=f'{area} observed mean')
            
            # M null distribution
            sns.histplot(data=null_mean_autocorrs[area]['m'], kde=True, ax=axes[1,1],
                         label=f'{area} null', alpha=0.3)
            axes[1,1].axvline(np.mean(m_autocorrs[area]), color='r' if area=='CA1' else 'g',
                              linestyle='--', label=f'{area} observed mean')
        
        axes[1,0].set_title('Null Distribution of Mean Tau Autocorrelations')
        axes[1,0].set_xlabel('Mean Autocorrelation Coefficient (τ)')
        axes[1,0].set_ylabel('Count')
        axes[1,0].legend()
        
        axes[1,1].set_title('Null Distribution of Mean Branching Factor Autocorrelations')
        axes[1,1].set_xlabel('Mean Autocorrelation Coefficient (m)')
        axes[1,1].set_ylabel('Count')
        axes[1,1].legend()
        
        plt.tight_layout()
        
        # Create formatted results table
        formatted_data = []
        for area in areas:
            # Tau statistics
            observed_tau_mean = np.mean(tau_autocorrs[area])
            null_tau_means = null_mean_autocorrs[area]['tau']
            p_value_tau = np.mean(np.abs(null_tau_means) >= np.abs(observed_tau_mean))
            
            formatted_data.append({
                'Area': area,
                'Measure': 'Neural Timescale',
                'Observed Mean': f"{observed_tau_mean:.3f}",
                'Null Mean': f"{np.mean(null_tau_means):.3f}",
                'p-value': f"{p_value_tau:.3e}",
                'CI 95%': f"[{np.percentile(null_tau_means, 2.5):.3f}, {np.percentile(null_tau_means, 97.5):.3f}]"
            })
            
            # M statistics
            observed_m_mean = np.mean(m_autocorrs[area])
            null_m_means = null_mean_autocorrs[area]['m']
            p_value_m = np.mean(np.abs(null_m_means) >= np.abs(observed_m_mean))
            
            formatted_data.append({
                'Area': area,
                'Measure': 'Branching Factor',
                'Observed Mean': f"{observed_m_mean:.3f}",
                'Null Mean': f"{np.mean(null_m_means):.3f}",
                'p-value': f"{p_value_m:.3e}",
                'CI 95%': f"[{np.percentile(null_m_means, 2.5):.3f}, {np.percentile(null_m_means, 97.5):.3f}]"
            })

        # Create DataFrame
        table_df = pd.DataFrame(formatted_data)
        
        # Apply styling
        styled_df = (table_df.style
                    .set_properties(**{
                        'text-align': 'center',
                        'font-size': '11pt',
                        'font-family': 'Arial',
                        'border': '2px solid black'
                    })
                    .set_table_styles([
                        {'selector': 'table',
                         'props': [('border', '2px solid black')]},
                        {'selector': 'th',
                         'props': [('background-color', '#f0f0f0'),
                                 ('font-weight', 'bold'),
                                 ('text-align', 'center'),
                                 ('border-bottom', '2px solid black'),
                                 ('white-space', 'pre-wrap')]},
                        {'selector': 'td',
                         'props': [('white-space', 'pre-wrap')]},
                        {'selector': 'caption',
                         'props': [('caption-side', 'top'),
                                 ('font-size', '14pt'),
                                 ('font-weight', 'bold'),
                                 ('margin-bottom', '10px')]}
                    ])
                    .set_caption('Within-Area Autocorrelation Analysis Results')
                    .hide(axis='index'))
        
        # Display the styled table
        display(styled_df)
        
        return {
            'tau_autocorrs': tau_autocorrs,
            'm_autocorrs': m_autocorrs,
            'null_mean_autocorrs': null_mean_autocorrs,
            'figure': fig,
            'styled_results': styled_df
        }

def calculate_between_area_autocorrelations_subsequent_chunks(df, n_permutations=1000):
    """
    Calculates between-area autocorrelations (CA1→CA3 and CA3→CA1) with permutation tests.
    
    Parameters:
    -----------
    df : pandas DataFrame
        Input DataFrame containing time series data
    n_permutations : int
        Number of permutations for the null distribution
    """
    # Initialize storage
    autocorrs = {
        'CA1_to_CA3': {'tau': [], 'm': []},
        'CA3_to_CA1': {'tau': [], 'm': []}
    }
    null_mean_autocorrs = {
        'CA1_to_CA3': {'tau': [], 'm': []},
        'CA3_to_CA1': {'tau': [], 'm': []}
    }
    
    # Set up context managers to suppress unwanted outputs
    import warnings
    import matplotlib.pyplot as plt
    from contextlib import contextmanager
    
    @contextmanager
    def suppress_outputs():
        """Context manager to suppress unwanted outputs"""
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            plt.ioff()  # Turn off interactive plotting
            yield
            plt.ion()  # Turn interactive plotting back on
    
    # Run the analysis with suppressed outputs
    with suppress_outputs():
        # Calculate observed autocorrelations
        for name, group in df.groupby(['animal', 'day', 'epoch']):
            ca1_data = group[group['area'] == 'CA1'].sort_values('time_chunk')
            ca3_data = group[group['area'] == 'CA3'].sort_values('time_chunk')
            
            if len(ca1_data) > 10 and len(ca3_data) > 10:
                # Merge data on time chunk to ensure matching time chunks
                merged_data = pd.merge(ca1_data, ca3_data, on='time_chunk', how='inner', suffixes=('_CA1', '_CA3'))
                
                # Extract tau and branching factor values for merged data
                ca1_tau = merged_data['tau_CA1'].values
                ca3_tau = merged_data['tau_CA3'].values
                ca1_m = merged_data['branching_factor_CA1'].values
                ca3_m = merged_data['branching_factor_CA3'].values
                
                # Calculate CA1→CA3 autocorrelations
                tau_corr_1to3 = np.corrcoef(ca1_tau[:-1], ca3_tau[1:])[0,1]
                m_corr_1to3 = np.corrcoef(ca1_m[:-1], ca3_m[1:])[0,1]
                
                # Calculate CA3→CA1 autocorrelations
                tau_corr_3to1 = np.corrcoef(ca3_tau[:-1], ca1_tau[1:])[0,1]
                m_corr_3to1 = np.corrcoef(ca3_m[:-1], ca1_m[1:])[0,1]
                
                # Store valid correlations
                if not np.isnan(tau_corr_1to3):
                    autocorrs['CA1_to_CA3']['tau'].append(tau_corr_1to3)
                if not np.isnan(m_corr_1to3):
                    autocorrs['CA1_to_CA3']['m'].append(m_corr_1to3)
                if not np.isnan(tau_corr_3to1):
                    autocorrs['CA3_to_CA1']['tau'].append(tau_corr_3to1)
                if not np.isnan(m_corr_3to1):
                    autocorrs['CA3_to_CA1']['m'].append(m_corr_3to1)
        
        # Permutation test
        for perm in range(n_permutations):
            perm_autocorrs = {
                'CA1_to_CA3': {'tau': [], 'm': []},
                'CA3_to_CA1': {'tau': [], 'm': []}
            }
            
            for name, group in df.groupby(['animal', 'day', 'epoch']):
                ca1_data = group[group['area'] == 'CA1'].sort_values('time_chunk')
                ca3_data = group[group['area'] == 'CA3'].sort_values('time_chunk')
                
                if len(ca1_data) > 10 and len(ca3_data) > 10:
                    # Merge data on time chunk to ensure matching time chunks
                    merged_data = pd.merge(ca1_data, ca3_data, on='time_chunk', how='inner', suffixes=('_CA1', '_CA3'))
                    
                    # Get and shuffle time series
                    ca1_tau = np.random.permutation(merged_data['tau_CA1'].values)
                    ca3_tau = np.random.permutation(merged_data['tau_CA3'].values)
                    ca1_m = np.random.permutation(merged_data['branching_factor_CA1'].values)
                    ca3_m = np.random.permutation(merged_data['branching_factor_CA3'].values)
                    
                    # Calculate shuffled correlations
                    tau_corr_1to3 = np.corrcoef(ca1_tau[:-1], ca3_tau[1:])[0,1]
                    m_corr_1to3 = np.corrcoef(ca1_m[:-1], ca3_m[1:])[0,1]
                    tau_corr_3to1 = np.corrcoef(ca3_tau[:-1], ca1_tau[1:])[0,1]
                    m_corr_3to1 = np.corrcoef(ca3_m[:-1], ca1_m[1:])[0,1]
                    
                    # Store valid correlations
                    if not np.isnan(tau_corr_1to3):
                        perm_autocorrs['CA1_to_CA3']['tau'].append(tau_corr_1to3)
                    if not np.isnan(m_corr_1to3):
                        perm_autocorrs['CA1_to_CA3']['m'].append(m_corr_1to3)
                    if not np.isnan(tau_corr_3to1):
                        perm_autocorrs['CA3_to_CA1']['tau'].append(tau_corr_3to1)
                    if not np.isnan(m_corr_3to1):
                        perm_autocorrs['CA3_to_CA1']['m'].append(m_corr_3to1)
            
            # Store mean of permutation
            for direction in ['CA1_to_CA3', 'CA3_to_CA1']:
                for measure in ['tau', 'm']:
                    if perm_autocorrs[direction][measure]:
                        null_mean_autocorrs[direction][measure].append(
                            np.mean(perm_autocorrs[direction][measure])
                        )
    results = {
        'autocorrs': autocorrs,
        'null_mean_autocorrs': null_mean_autocorrs
    }
    display_between_area_results(results)

def display_between_area_results(results):
    """
    Formats and displays the results from between-area autocorrelation analysis.
    
    Parameters:
    -----------
    results : dict
        Output from calculate_between_area_autocorrelations
    """
    # Prepare results for both directions
    directions = ['CA1_to_CA3', 'CA3_to_CA1']
    measures = ['tau', 'm']
    
    for direction in directions:
        formatted_data = []
        
        for measure in measures:
            measure_name = 'Neural Timescale' if measure == 'tau' else 'Branching Factor'
            observed_mean = np.mean(results['autocorrs'][direction][measure])
            null_means = results['null_mean_autocorrs'][direction][measure]
            p_value = np.mean(np.abs(null_means) >= np.abs(observed_mean))
            
            formatted_data.append({
                'Measure': measure_name,
                'Observed Mean': f"{observed_mean:.3f}",
                'Null Mean': f"{np.mean(null_means):.3f}",
                'p-value': f"{p_value:.3e}",
                'CI 95%': f"[{np.percentile(null_means, 2.5):.3f}, {np.percentile(null_means, 97.5):.3f}]"
            })
        
        # Create DataFrame
        table_df = pd.DataFrame(formatted_data)
        
        # Apply styling
        styled_df = (table_df.style
                    .set_properties(**{
                        'text-align': 'center',
                        'font-size': '11pt',
                        'font-family': 'Arial',
                        'border': '2px solid black'
                    })
                    .set_table_styles([
                        {'selector': 'table',
                         'props': [('border', '2px solid black')]},
                        {'selector': 'th',
                         'props': [('background-color', '#f0f0f0'),
                                 ('font-weight', 'bold'),
                                 ('text-align', 'center'),
                                 ('border-bottom', '2px solid black')]},
                        {'selector': 'caption',
                         'props': [('caption-side', 'top'),
                                 ('font-size', '14pt'),
                                 ('font-weight', 'bold'),
                                 ('margin-bottom', '10px')]}
                    ])
                    .set_caption(f'Analysis Results ({direction})')
                    .hide(axis='index'))
        
        display(styled_df)
        print("\n")

